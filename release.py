#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import base64
import os
import re
import shutil
import ssl
import time
import urllib.error
import urllib.request
from collections import defaultdict

# ================= é…ç½®åŒºåŸŸ =================

# ğŸ”´ Debug å¼€å…³ï¼šè®¾ç½®ä¸º True åï¼Œç”Ÿæˆçš„æ–‡ä»¶å°†åŒ…å«æ¥æºæ³¨é‡Š
DEBUG_MODE = True

# å·¥ä½œç›®å½•
WORK_DIR = "./gfwlist2_output"
TEMP_DIR = "./Temp_Python"

# [éªŒè¯ç”¨æ­£åˆ™] ä¸¥æ ¼æ ¡éªŒ
VALID_DOMAIN_PATTERN = re.compile(r'^[a-z0-9](?:[a-z0-9.-]*[a-z0-9])?\.([a-z]{2,13}|[a-z0-9-]{2,30}\.[a-z]{2,3})$')
# [æå–ç”¨æ­£åˆ™] ç²—ç•¥æå–
EXTRACT_PATTERN = re.compile(rb'[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}')

# å¿½ç•¥ SSL éªŒè¯
ssl._create_default_https_context = ssl._create_unverified_context

# æºåˆ—è¡¨å®šä¹‰
SOURCES = {
    "cnacc_domain": [
        "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/apple-cn.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Apple/Apple_Classical_No_Resolve.yaml",
        "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/direct-list.txt",
        "https://raw.githubusercontent.com/madswaord/surgejourney/refs/heads/main/Clash/Ruleset/Binance.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/GoogleFCM/GoogleFCM.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/GovCN/GovCN.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/China/China_Domain.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/ChinaMaxNoIP/ChinaMaxNoIP_Domain.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/DouYin/DouYin.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Tencent/Tencent.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/UnionPay/UnionPay.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/OPPO/OPPO.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Vivo/Vivo.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/XiaoMi/XiaoMi.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/XiaoHongShu/XiaoHongShu.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/ChinaUnicom/ChinaUnicom.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/ChinaTelecom/ChinaTelecom.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/ChinaMobile/ChinaMobile.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/ChinaNoMedia/ChinaNoMedia_Domain.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/JingDong/JingDong.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/SteamCN/SteamCN.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Binance/Binance_No_Resolve.yaml",
        "https://raw.githubusercontent.com/felixonmars/dnsmasq-china-list/master/accelerated-domains.china.conf",
        "https://raw.githubusercontent.com/felixonmars/dnsmasq-china-list/master/apple.china.conf",
    ],
    "gfwlist_base64": [
        "https://raw.githubusercontent.com/Loukky/gfwlist-by-loukky/master/gfwlist.txt",
        "https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt",
        "https://raw.githubusercontent.com/poctopus/gfwlist-plus/master/gfwlist-plus.txt",
    ],
    "gfwlist_domain": [
        "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/gfw.txt",
        "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/greatfire.txt",
        "https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/proxy-list.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Proxy/Proxy_Domain_For_Clash.txt",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/refs/heads/master/rule/Clash/Crypto/Crypto.yaml",
        "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/Global/Global_Domain.list",
        "https://raw.githubusercontent.com/pexcn/gfwlist-extras/master/gfwlist-extras.txt",
    ],
    "modify": [
        "https://raw.githubusercontent.com/Seed680/gfwlist_merge/refs/heads/main/data_modify.conf"
    ]
}

# å…¨å±€æ•°æ®å­˜å‚¨
DATA_STORE = {
    "cnacc_raw": set(),
    "gfwlist_raw": set(),
    "modify_rules": []
}

# ğŸŸ¢ æº¯æºè¿½è¸ªå™¨ï¼š { "google.com": {"gfwlist.txt", "google-cn.txt"} }
SOURCE_TRACKER = defaultdict(set)

# ================= è¾…åŠ©å‡½æ•° =================

def download_url(url, retries=3):
    """ä¸‹è½½ URL å†…å®¹"""
    print(f"æ­£åœ¨ä¸‹è½½: {url}")
    for i in range(retries):
        try:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=15) as response:
                return response.read()
        except Exception as e:
            print(f"ä¸‹è½½å¤±è´¥ ({i+1}/{retries}): {e}")
            time.sleep(1)
    return None

def clean_domain(domain):
    """æ¸…æ´—åŸŸåå¹¶éªŒè¯"""
    if isinstance(domain, bytes):
        domain = domain.decode('utf-8', errors='ignore')

    if not domain: return ""
    d = domain.strip().lower()

    # ç§»é™¤å¸¸è§å‰ç¼€/å¹²æ‰°
    d = re.sub(r'^https?://', '', d)
    d = d.replace('domain:', '').replace('full:', '').replace('server=/', '')
    d = d.replace('/114.114.114.114', '').replace('|', '')

    if d.startswith('.'): d = d[1:]

    if VALID_DOMAIN_PATTERN.match(d):
        return d
    return ""

def get_root_domain(domain):
    """è·å–æ ¹åŸŸå"""
    parts = domain.split('.')
    if len(parts) >= 2:
        return f"{parts[-2]}.{parts[-1]}"
    return domain

def extract_domains_from_line(line_content):
    """ä»å•è¡Œæ–‡æœ¬æå–åŸŸå (ç”¨äº modify è§„åˆ™)"""
    raw_domains = line_content.replace(',', ' ').split()
    cleaned = []
    for d in raw_domains:
        cd = clean_domain(d)
        if cd: cleaned.append(cd)
    return cleaned

def get_filename_from_url(url):
    """ä» URL æå–æ–‡ä»¶åç”¨äºæ ‡è¯†"""
    if not url: return "unknown"
    return url.split('/')[-1]

# ================= æ ¸å¿ƒé€»è¾‘ =================

def get_data():
    """ä¸‹è½½å¹¶é¢„å¤„ç†æ•°æ® (å¸¦æº¯æºåŠŸèƒ½)"""
    print(">>> å¼€å§‹ä¸‹è½½æ•°æ®...")

    # é€šç”¨å¤„ç†å‡½æ•°ï¼šæŒ‰è¡Œå¤„ç† + è®°å½•æ¥æº
    def process_content_by_line(content, target_set, source_tag):
        if not content: return
        try:
            text = content.decode('utf-8', errors='ignore')
            for line in text.splitlines():
                line = line.strip()
                if not line: continue
                if line.startswith(("#", "//")): continue # å¿½ç•¥æ³¨é‡Š
                
                matches = EXTRACT_PATTERN.findall(line.encode('utf-8'))
                for m in matches:
                    d = clean_domain(m)
                    if d: 
                        target_set.add(d)
                        # ğŸŸ¢ è®°å½•æ¥æº
                        SOURCE_TRACKER[d].add(source_tag)
        except Exception as e:
            print(f"å¤„ç†å‡ºé”™: {e}")

    # 1. ä¸‹è½½ cnacc_domain
    for url in SOURCES["cnacc_domain"]:
        content = download_url(url)
        # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ¥æºæ ‡ç­¾
        fname = get_filename_from_url(url)
        process_content_by_line(content, DATA_STORE["cnacc_raw"], fname)

    # 2. ä¸‹è½½ gfwlist_base64
    for url in SOURCES["gfwlist_base64"]:
        content = download_url(url)
        fname = get_filename_from_url(url)
        if content:
            try:
                decoded = base64.b64decode(content)
                process_content_by_line(decoded, DATA_STORE["gfwlist_raw"], fname)
            except:
                print(f"Base64 è§£ç å¤±è´¥: {url}")

    # 3. ä¸‹è½½ gfwlist_domain
    for url in SOURCES["gfwlist_domain"]:
        content = download_url(url)
        fname = get_filename_from_url(url)
        process_content_by_line(content, DATA_STORE["gfwlist_raw"], fname)

    # 4. ä¸‹è½½ Modify æ–‡ä»¶
    for url in SOURCES["modify"]:
        content = download_url(url)
        if content:
            text = content.decode('utf-8', errors='ignore')
            for line in text.splitlines():
                line_str = line.strip()
                if line_str and not line_str.startswith(("#", "//")):
                    DATA_STORE["modify_rules"].append(line_str)

    print(f"ä¸‹è½½å®Œæˆã€‚CNåŸå§‹æ•°é‡: {len(DATA_STORE['cnacc_raw'])}, GFWåŸå§‹æ•°é‡: {len(DATA_STORE['gfwlist_raw'])}")

def analyse_data():
    """åˆ†ææ•°æ®"""
    print(">>> å¼€å§‹åˆ†ææ•°æ®...")

    cn_add = set()
    cn_remove = set()
    gfw_add = set()
    gfw_remove = set()

    # è¾…åŠ©å‡½æ•°ï¼šè®°å½•è‡ªå®šä¹‰è§„åˆ™çš„æ¥æº
    def add_with_tracking(domain_set, domains, tag):
        for d in domains:
            domain_set.add(d)
            SOURCE_TRACKER[d].add(tag)

    # è§£æ Modify è§„åˆ™
    for rule in DATA_STORE["modify_rules"]:
        # æå–å½“å‰è¡Œçš„æ‰€æœ‰åŸŸå
        domains_in_line = []
        
        # åˆ¤æ–­æŒ‡ä»¤ç±»å‹å¹¶å»é™¤æŒ‡ä»¤å‰ç¼€
        rule_body = ""
        action_type = ""
        
        if rule.startswith("@++"): 
            rule_body = rule[3:]
            action_type = "cn_add"
        elif rule.startswith("@--"):
            rule_body = rule[3:]
            action_type = "cn_remove"
        elif rule.startswith("!++"):
            rule_body = rule[3:]
            action_type = "gfw_add"
        elif rule.startswith("!--"):
            rule_body = rule[3:]
            action_type = "gfw_remove"
        elif rule.startswith("@+"):
            rule_body = rule[2:]
            action_type = "cn_force" # CN+ GFW-
        elif rule.startswith("!+"):
            rule_body = rule[2:]
            action_type = "gfw_force" # GFW+ CN-

        if action_type:
            domains_in_line = extract_domains_from_line(rule_body)
            # æ ‡è®°æ¥æºä¸º [My_Custom_Rule]
            custom_tag = "[My_Custom_Rule]"
            
            if action_type == "cn_add":
                add_with_tracking(cn_add, domains_in_line, custom_tag)
            elif action_type == "cn_remove":
                add_with_tracking(cn_remove, domains_in_line, custom_tag)
            elif action_type == "gfw_add":
                add_with_tracking(gfw_add, domains_in_line, custom_tag)
            elif action_type == "gfw_remove":
                add_with_tracking(gfw_remove, domains_in_line, custom_tag)
            elif action_type == "cn_force":
                add_with_tracking(cn_add, domains_in_line, custom_tag)
                add_with_tracking(gfw_remove, domains_in_line, custom_tag)
            elif action_type == "gfw_force":
                add_with_tracking(gfw_add, domains_in_line, custom_tag)
                add_with_tracking(cn_remove, domains_in_line, custom_tag)

    # è¿‡æ»¤å‡½æ•°
    def filter_list_with_suffix(source_set, remove_set):
        result = set()
        remove_suffixes = tuple("." + d for d in remove_set)
        for d in source_set:
            if d in remove_set: continue
            if d.endswith(remove_suffixes): continue
            result.add(d)
        return result

    print("åº”ç”¨ç§»é™¤è§„åˆ™...")
    cn_filtered = filter_list_with_suffix(DATA_STORE["cnacc_raw"], cn_remove)
    gfw_filtered = filter_list_with_suffix(DATA_STORE["gfwlist_raw"], gfw_remove)

    # äº¤å‰å»é‡
    gfw_filtered = gfw_filtered - cn_filtered

    # åº”ç”¨å¢åŠ è§„åˆ™
    cn_final = cn_filtered | cn_add
    gfw_final = gfw_filtered | gfw_add

    # ç”Ÿæˆ Lite åˆ—è¡¨
    lite_cn_final = {get_root_domain(d) for d in cn_final}
    lite_gfw_final = {get_root_domain(d) for d in gfw_final}

    # ä¿å­˜
    DATA_STORE["cn_final"] = sorted(list(cn_final))
    DATA_STORE["gfw_final"] = sorted(list(gfw_final))
    DATA_STORE["lite_cn_final"] = sorted(list(lite_cn_final))
    DATA_STORE["lite_gfw_final"] = sorted(list(lite_gfw_final))
    
    print(f"åˆ†æå®Œæˆã€‚CN: {len(DATA_STORE['cn_final'])}, GFW: {len(DATA_STORE['gfw_final'])}")

def output_data():
    """ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶ (Debug æ¨¡å¼ä¸‹åŒ…å«æ³¨é‡Š)"""
    print(">>> å¼€å§‹ç”Ÿæˆè§„åˆ™æ–‡ä»¶...")

    target_dirs = ["smartdns", "clash", "domain"]
    for sw in target_dirs:
        os.makedirs(os.path.join(WORK_DIR, f"gfwlist2{sw}"), exist_ok=True)

    tasks = [
        {"sw": "smartdns", "file": "black", "mode": "full", "group": "GFW"},
        {"sw": "smartdns", "file": "black", "mode": "lite", "group": "GFW"},
        {"sw": "smartdns", "file": "white", "mode": "full", "group": "CN"},
        {"sw": "smartdns", "file": "white", "mode": "lite", "group": "CN"},
        {"sw": "clash", "file": "black", "mode": "full"},
        {"sw": "clash", "file": "black", "mode": "lite"},
        {"sw": "clash", "file": "white", "mode": "full"},
        {"sw": "clash", "file": "white", "mode": "lite"},
        {"sw": "domain", "file": "black", "mode": "full"},
        {"sw": "domain", "file": "black", "mode": "lite"},
        {"sw": "domain", "file": "white", "mode": "full"},
        {"sw": "domain", "file": "white", "mode": "lite"},
    ]

    for task in tasks:
        sw = task.get("sw")
        mode = task.get("mode")
        ftype = task.get("file")
        
        data_list = []
        is_lite = "lite" in mode
        
        if ftype == "black":
            data_list = DATA_STORE["lite_gfw_final"] if is_lite else DATA_STORE["gfw_final"]
        elif ftype == "white":
            data_list = DATA_STORE["lite_cn_final"] if is_lite else DATA_STORE["cn_final"]

        ext = "txt"
        if sw == "clash": ext = "yaml"
        elif sw == "smartdns": ext = "conf"
        
        filename = f"{ftype}list_{mode}.{ext}"
        filepath = os.path.join(WORK_DIR, f"gfwlist2{sw}", filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            if sw == "clash":
                f.write("payload:\n")
            
            for domain in data_list:
                # ğŸŸ¢ ç”Ÿæˆ Debug æ³¨é‡Š
                comment = ""
                if DEBUG_MODE:
                    # è·å–è¯¥åŸŸåçš„æ¥æºåˆ—è¡¨
                    sources = SOURCE_TRACKER.get(domain)
                    
                    # åªæœ‰åœ¨é lite æ¨¡å¼ï¼Œæˆ–è€… lite æ¨¡å¼ä¸‹åŸŸåæ­£å¥½å­˜åœ¨äº tracker ä¸­æ—¶æ‰èƒ½å‡†ç¡®æ˜¾ç¤º
                    # (Lite æ¨¡å¼æ˜¯é€šè¿‡ get_root_domain è®¡ç®—å‡ºæ¥çš„ï¼Œå¯èƒ½åœ¨ Tracker é‡Œæ²¡æœ‰ç›´æ¥é”®å€¼)
                    if not sources and is_lite:
                        # å°è¯•åœ¨ Lite æ¨¡å¼ä¸‹æ¨¡ç³ŠåŒ¹é… (å¯é€‰ï¼Œä½†ä¸ºäº†æ€§èƒ½æš‚æ—¶åªåŒ¹é…ç²¾ç¡®çš„)
                        pass
                        
                    if sources:
                        # å°† set è½¬æ¢ä¸ºé€—å·åˆ†éš”å­—ç¬¦ä¸²
                        src_str = ", ".join(sorted(list(sources)))
                        comment = f" # [{src_str}]"
                
                # å†™å…¥æ–‡ä»¶
                if sw == "clash":
                    f.write(f"  - DOMAIN-SUFFIX,{domain}{comment}\n")
                elif sw == "smartdns":
                    f.write(f"nameserver /{domain}/{task.get('group')}{comment}\n")
                elif sw == "domain":
                    f.write(f"{domain}{comment}\n")

    print(f"æ‰€æœ‰è§„åˆ™å·²ç”Ÿæˆè‡³: {WORK_DIR}")

# ================= ä¸»ç¨‹åº =================

def main():
    if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
    get_data()
    analyse_data()
    output_data()

if __name__ == "__main__":
    main()